{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ],
   "id": "30f7e5c3-b7ba-462f-9e85-6a004ad3f19d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import pickle\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoConfig,\n",
    "    BertModel,\n",
    ")\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers import AdamW\n",
    "import torch.optim as optim "
   ],
   "id": "d0aade82-6211-4c2b-8933-de0332d181cd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ],
   "id": "04edd9ad-49cd-474b-be60-c90f71b2735b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_dataset_tokenized.pkl', 'rb') as file:\n",
    "    train_dataset = pickle.load(file)\n",
    "\n",
    "with open('val_data_tokenized.pkl', 'rb') as file:\n",
    "    val_dataset = pickle.load(file)\n",
    "\n",
    "with open('test_data_tokenized.pkl', 'rb') as file:\n",
    "    test_dataset = pickle.load(file)\n",
    "\n",
    "with open('train_dataset_full_tokenized.pkl', 'rb') as file:\n",
    "    train_dataset_full = [pickle.load(file)]\n",
    "\n",
    "with open('augmented_train_dataset_tokenized.pkl', 'rb') as file:\n",
    "    train_dataset_augmented = pickle.load(file)\n",
    "\n",
    "with open('function_pickle.pkl', 'rb') as f:\n",
    "    create_training_arguments_and_optimizer = pickle.load(f)"
   ],
   "id": "da00bf24-11fe-4316-b52b-d3ae3d7353d2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the training arguments"
   ],
   "id": "3fddac14-392a-4e1b-abb9-7d000797ee2e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [5e-5, 4e-5, 3e-5, 2e-5]\n",
    "\n",
    "pre_trained_BERTmodel='bert-large-uncased'\n",
    "BERT_tokenizer=AutoTokenizer.from_pretrained(pre_trained_BERTmodel)"
   ],
   "id": "7bae8141-51cf-42e0-923f-7e21139f9c3f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying Bert for our classification Task"
   ],
   "id": "edc61075-f670-47da-bc2c-e52775571542"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModelWithCustomLossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertModelWithCustomLossFunction, self).__init__()\n",
    "        self.num_labels = 64\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            pre_trained_BERTmodel, num_labels=self.num_labels\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(1024, self.num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "\n",
    "        output = self.dropout(outputs.pooler_output)\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels)\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ],
   "id": "d53b29e9-424f-4bba-a812-ea34bd78caea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train_model function"
   ],
   "id": "c35c6b1f-3eaf-4459-84b1-75041134a9e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, args, val_dataset, test_dataset):\n",
    "    BERT_model = BertModelWithCustomLossFunction()\n",
    "    optimizer = AdamW(BERT_model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "    trainer = Trainer(\n",
    "        model=BERT_model,\n",
    "        args=args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=BERT_tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        optimizers=(optimizer,),\n",
    "    )\n",
    "    trainer.train()\n",
    "    evaluation_metrics = trainer.predict(test_dataset)\n",
    "    accuracy = evaluation_metrics.metrics['test_accuracy']\n",
    "    torch.cuda.empty_cache()\n",
    "    return accuracy"
   ],
   "id": "95de248b-001c-406e-a32e-a29c14d0f457"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up metrics for accuracy, precision, recall and f1"
   ],
   "id": "2f1ad8d2-49ec-48cc-bfa8-86907cff5572"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ],
   "id": "ff90dd84-2aa8-4be5-9c35-17d9193a653e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ],
   "id": "707b0ffe-fc27-4d3b-9e8c-cb9533cf41d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "2a6cfe33-1432-4411-9b81-6bce859be3e1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Full dataset Model"
   ],
   "id": "b3473e8c-9b84-4993-a9df-71838e510ac9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_data in train_dataset_full:\n",
    "    best_accuracy = 0\n",
    "    best_lr = learning_rates[0]\n",
    "    for lr in learning_rates:\n",
    "        args = create_training_arguments(lr)\n",
    "        accuracy = train_model(train_data, args, val_dataset, test_dataset)\n",
    "        if accuracy>best_accuracy:\n",
    "          best_lr = lr\n",
    "          best_accuracy = max(accuracy, best_accuracy)\n",
    "print(f\"Best Accuracy:{best_accuracy}\\n Best Learning Rate: {best_lr}\")"
   ],
   "id": "2e8b7e28-90e5-4ef5-912f-14feb694556e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training full few shot dataset model"
   ],
   "id": "75ec2530-1568-4d3b-8feb-115e1bf00aef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "for train_data in train_dataset:\n",
    "    for lr in [best_lr]:\n",
    "        args, optimizer = create_training_arguments(lr)\n",
    "        accuracy = train_model(train_data, args, val_dataset, test_dataset)\n",
    "        if accuracy>best_accuracy:\n",
    "          best_lr = lr\n",
    "          best_accuracy = max(accuracy, best_accuracy)\n",
    "print(f\"Best Accuracy:{best_accuracy}\")"
   ],
   "id": "a4c81e59-8450-4628-a3c7-616a4cee7f69"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model on Full few shot + Augmented dataset"
   ],
   "id": "3d9ddf50-84d9-4c74-9b33-c79540e6c606"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = 0\n",
    "for train_data in train_dataset_augmented:\n",
    "    for lr in [best_lr]::\n",
    "        args = create_training_arguments(lr)\n",
    "        accuracy = train_model(train_data, args, val_dataset, test_dataset)\n",
    "        if accuracy>best_accuracy:\n",
    "          best_lr = lr\n",
    "          best_accuracy = max(accuracy, best_accuracy)\n",
    "print(f\"Best Accuracy:{best_accuracy}\")"
   ],
   "id": "006c9f92-785a-46bd-b343-efd7100d3231"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
