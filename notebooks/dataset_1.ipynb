{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8c3dff1-e192-4df3-90ec-9124c8177c43"
      },
      "source": [
        "### importing libraries"
      ],
      "id": "c8c3dff1-e192-4df3-90ec-9124c8177c43"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9d4510f5-ae8d-4450-bc30-2feacf91c8d7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from zipfile import ZipFile"
      ],
      "id": "9d4510f5-ae8d-4450-bc30-2feacf91c8d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b09f125a-1aab-471e-9cb4-52c20ba821dd"
      },
      "source": [
        "### Clone the Github repository"
      ],
      "id": "b09f125a-1aab-471e-9cb4-52c20ba821dd"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "384f2b52-1e01-41ee-ae65-27a6d5f37753"
      },
      "outputs": [],
      "source": [
        "repository_url = 'https://github.com/xliuhw/NLU-Evaluation-Data/archive/refs/heads/master.zip'\n",
        "\n",
        "response = requests.get(repository_url)\n",
        "with open('repository.zip', 'wb') as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "with ZipFile('repository.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('repository')"
      ],
      "id": "384f2b52-1e01-41ee-ae65-27a6d5f37753"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arranging the relevant data\n",
        "\n",
        "There are two subfolders inside the repository (train and test) and these folder contains many csv files with name as inten.csv where intent is the different types of intents.\n",
        "\n",
        "We will be looping through all the csv files and then create a single file which would contain all the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "MliBbTOnn5_4"
      },
      "id": "MliBbTOnn5_4"
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for folder in [\"trainset\", \"testset/csv\"]:\n",
        "  csv_files = [file for file in os.listdir(f'repository/NLU-Evaluation-Data-master/CrossValidation/autoGeneFromRealAnno/autoGene_2018_03_22-13_01_25_169/CrossValidation/KFold_1/{folder}') if file.endswith('.csv')]\n",
        "  merged_df = pd.DataFrame()\n",
        "  for csv_file in csv_files:\n",
        "      file_path = f'repository/NLU-Evaluation-Data-master/CrossValidation/autoGeneFromRealAnno/autoGene_2018_03_22-13_01_25_169/CrossValidation/KFold_1/{folder}' '/' + csv_file\n",
        "      df = pd.read_csv(file_path,delimiter=\";\")\n",
        "      merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
        "  data.append(merged_df)"
      ],
      "metadata": {
        "id": "fi6ZM4Y0n5cf"
      },
      "id": "fi6ZM4Y0n5cf",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extracting the relevent columns and then saving the dataframes to a csv file"
      ],
      "metadata": {
        "id": "FeUySPwsqj93"
      },
      "id": "FeUySPwsqj93"
    },
    {
      "cell_type": "code",
      "source": [
        "for i, merged_df in enumerate(data):\n",
        "  merged_df[\"merged\"] = merged_df[\"scenario\"] + \"_\" + merged_df[\"intent\"]\n",
        "  merged_df = merged_df[[\"answer_from_user\", \"merged\"]]\n",
        "  merged_df.columns = [\"speech_text\",\"intent\"]\n",
        "  if i == 0:\n",
        "    merged_df.to_csv('train.csv')\n",
        "  else:\n",
        "    merged_df.to_csv('test.csv')"
      ],
      "metadata": {
        "id": "6fcJMjJ2rZB0"
      },
      "id": "6fcJMjJ2rZB0",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a13b8427-0e09-4b59-89d0-75ad84386baa"
      },
      "source": [
        "The above cell will produce two csv files as output.\n",
        "\n",
        "-   train.csv\n",
        "\n",
        "-   test.csv"
      ],
      "id": "a13b8427-0e09-4b59-89d0-75ad84386baa"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}