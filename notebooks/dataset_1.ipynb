{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data"
   ],
   "id": "2724bad9-7cec-4e0c-a571-5630161523a5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing libraries"
   ],
   "id": "c8c3dff1-e192-4df3-90ec-9124c8177c43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ],
   "id": "9d4510f5-ae8d-4450-bc30-2feacf91c8d7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching and storing the data"
   ],
   "id": "b09f125a-1aab-471e-9cb4-52c20ba821dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_HEADER = [\"text\", \"category\"]\n",
    "PATTERNS = {\n",
    "    \"train\": \"https://raw.githubusercontent.com/xliuhw/NLU-Evaluation-Data\"\n",
    "             \"/master/CrossValidation/autoGeneFromRealAnno/autoGene_2018_03_\"\n",
    "             \"22-13_01_25_169/CrossValidation/KFold_1/trainset/{f}\",\n",
    "    \"test\": \"https://raw.githubusercontent.com/xliuhw/NLU-Evaluation-Data/\"\n",
    "            \"master/CrossValidation/autoGeneFromRealAnno/autoGene_2018_03_\"\n",
    "            \"22-13_01_25_169/CrossValidation/KFold_1/testset/csv/{f}\"\n",
    "}\n",
    "\n",
    "LIST_OF_FILES = (\n",
    "    'alarm_query.csv\\nalarm_remove.csv\\nalarm_set.csv\\naudio_volum'\n",
    "    'e_down.csv\\naudio_volume_mute.csv\\naudio_volume_up.csv\\ncalend'\n",
    "    'ar_query.csv\\t\\ncalendar_remove.csv\\t\\ncalendar_set.csv\\t\\ncoo'\n",
    "    'king_recipe.csv\\t\\ndatetime_convert.csv\\t\\ndatetime_query.csv'\n",
    "    '\\t\\nemail_addcontact.csv\\t\\nemail_query.csv\\t\\nemail_querycon'\n",
    "    'tact.csv\\t\\nemail_sendemail.csv\\t\\ngeneral_affirm.csv\\t\\ngener'\n",
    "    'al_commandstop.csv\\t\\ngeneral_confirm.csv\\t\\ngeneral_dontcare.'\n",
    "    'csv\\t\\ngeneral_explain.csv\\t\\ngeneral_joke.csv\\t\\ngeneral_neg'\n",
    "    'ate.csv\\t\\ngeneral_praise.csv\\t\\ngeneral_quirky.csv\\t\\ngenera'\n",
    "    'l_repeat.csv\\t\\niot_cleaning.csv\\t\\niot_coffee.csv\\t\\niot_hue'\n",
    "    '_lightchange.csv\\t\\niot_hue_lightdim.csv\\t\\niot_hue_lightoff.'\n",
    "    'csv\\t\\niot_hue_lighton.csv\\t\\niot_hue_lightup.csv\\t\\niot_wemo_'\n",
    "    'off.csv\\t\\niot_wemo_on.csv\\t\\nlists_createoradd.csv\\t\\nlists_'\n",
    "    'query.csv\\t\\nlists_remove.csv\\t\\nmusic_likeness.csv\\t\\nmusic_q'\n",
    "    'uery.csv\\t\\nmusic_settings.csv\\t\\nnews_query.csv\\t\\nplay_audio'\n",
    "    'book.csv\\t\\nplay_game.csv\\t\\nplay_music.csv\\t\\nplay_podcasts.'\n",
    "    'csv\\t\\nplay_radio.csv\\t\\nqa_currency.csv\\t\\nqa_definition.csv'\n",
    "    '\\t\\nqa_factoid.csv\\t\\nqa_maths.csv\\t\\nqa_stock.csv\\t\\nrecomme'\n",
    "    'ndation_events.csv\\t\\nrecommendation_locations.csv\\t\\nrecomme'\n",
    "    'ndation_movies.csv\\t\\nsocial_post.csv\\t\\nsocial_query.csv\\t\\n'\n",
    "    'takeaway_order.csv\\t\\ntakeaway_query.csv\\t\\ntransport_query.c'\n",
    "    'sv\\t\\ntransport_taxi.csv\\t\\ntransport_ticket.csv\\t\\ntransport'\n",
    "    '_traffic.csv\\t\\nweather_query.csv\\t'.split())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _get_category_rows(fname: str, set_name: str):\n",
    "    pattern = PATTERNS[set_name]\n",
    "    url = pattern.format(f=fname)\n",
    "    request = requests.get(url)\n",
    "\n",
    "    reader = csv.reader(\n",
    "        io.StringIO(request.content.decode(\"utf-8\")), delimiter=\";\"\n",
    "    )\n",
    "    first_row = next(reader)\n",
    "    scenario_i, intent_i = first_row.index(\"scenario\"), first_row.index(\n",
    "        \"intent\")\n",
    "    answer_i = first_row.index(\"answer_from_anno\")\n",
    "\n",
    "    rows = []\n",
    "    for row in reader:\n",
    "        text = row[answer_i]\n",
    "        category = f\"{row[scenario_i]}_{row[intent_i]}\"\n",
    "        rows.append([text, category])\n",
    "    return rows\n",
    "\n",
    "\n",
    "def _get_final_rows(set_name: str):\n",
    "    final_rows = [_HEADER]\n",
    "    for f in tqdm(LIST_OF_FILES):\n",
    "        final_rows += _get_category_rows(f, set_name)\n",
    "    return final_rows\n",
    "\n",
    "\n",
    "def _write_data_into_file(path, rows):\n",
    "    with open(path, \"w\") as data_file:\n",
    "        writer = csv.writer(data_file, quoting=csv.QUOTE_ALL)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "\n",
    "def _main():\n",
    "    data_dir = os.getcwd()\n",
    "\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.mkdir(data_dir)\n",
    "\n",
    "    print(\"Getting train data\")\n",
    "    train_rows = _get_final_rows(set_name=\"train\")\n",
    "    _write_data_into_file(\n",
    "        path=os.path.join(data_dir, \"train.csv\"),\n",
    "        rows=train_rows\n",
    "    )\n",
    "\n",
    "    print(\"Getting test data\")\n",
    "    test_rows = _get_final_rows(set_name=\"test\")\n",
    "    _write_data_into_file(\n",
    "        path=os.path.join(data_dir, \"test.csv\"),\n",
    "        rows=test_rows\n",
    "    )\n",
    "\n",
    "    print(\"Creating categories.json file\")\n",
    "    _, train_cats = zip(*train_rows[1:])\n",
    "    _, test_cats = zip(*test_rows[1:])\n",
    "    categories = sorted(list(\n",
    "        set(train_cats) | set(test_cats)\n",
    "    ))\n",
    "    with open(os.path.join(data_dir, \"categories.json\"), \"w\") as f:\n",
    "        json.dump(categories, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _main()\n",
    "\n"
   ],
   "id": "384f2b52-1e01-41ee-ae65-27a6d5f37753"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell will produce two csv files as output.\n",
    "\n",
    "-   train.csv\n",
    "\n",
    "-   test.csv"
   ],
   "id": "a13b8427-0e09-4b59-89d0-75ad84386baa"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
