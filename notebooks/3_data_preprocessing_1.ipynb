{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing relevent libraries"
   ],
   "id": "6dd9b8d5-a2e2-43c5-a6d4-953e6b18b3bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "seed=123"
   ],
   "id": "f6f96fac-15bb-42a8-b545-90b9da62e127"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the train and test data"
   ],
   "id": "4d62e6b1-757a-4a96-99cc-077dea7ad079"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ],
   "id": "3739f178-e7bc-4b84-ad14-2092eb8f0a86"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels"
   ],
   "id": "5d4bc88b-7901-48ca-8b36-bd67c9d76259"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "train_data['intent']=le.fit_transform(train_data['intent'])\n",
    "test_data['intent']=le.transform(test_data['intent'])\n",
    "train_data = train_data.drop(\"Unnamed: 0\", axis=1)"
   ],
   "id": "2b09f580-0a0e-4e0c-bdf4-57b13da22a26"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the training data to train and validation"
   ],
   "id": "7f42c643-0c6b-4e8b-8991-7130484b83b1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,val_data=train_test_split(train_data,test_size=0.10 ,random_state=seed, shuffle=True)"
   ],
   "id": "29a03787-fd8d-4052-8d9e-17a342cae9d4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random 30 samples from training data"
   ],
   "id": "2e2a46bf-28d8-445c-833b-2c53d60eb456"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the unique intent\n",
    "unique_labels = df_train['intent'].unique()\n",
    "# Creating an empty dataframe to store all the values\n",
    "sampled_df = pd.DataFrame()\n",
    "#Iterating through each label and take random 30 samples from it\n",
    "for label in unique_labels:\n",
    "    label_df = df_train[df_train['intent'] == label]\n",
    "    samples = label_df.sample(n=30, random_state=seed)\n",
    "    sampled_df = sampled_df.append(samples)\n",
    "sampled_df.reset_index(drop=True, inplace=True)"
   ],
   "id": "4dfe76d4-2bfe-4ab1-ab3b-4c59e98ffac4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create 3 unique 10-shot dataset from previous sampled data"
   ],
   "id": "0441c8fb-c221-4c32-895b-35dfd9b00289"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sampled_df\n",
    "# Create a column sample and mark it all as False and when you pick a sample mark them as True. This will make sure that you are not repeating the same sample again.\n",
    "df['sampled'] = False\n",
    "\n",
    "#creating a list to store the 10 shot dataset\n",
    "training_datasets = []\n",
    "\n",
    "for i in range(3):\n",
    "    dataset = pd.DataFrame()\n",
    "    for label in df['intent'].unique():\n",
    "        label_df = df[(df['intent'] == label) & (df['sampled'] == False)]\n",
    "        if len(label_df) >= 10:\n",
    "            samples = label_df.sample(n=10)\n",
    "            df.loc[samples.index, 'sampled'] = True\n",
    "            dataset = pd.concat([dataset, samples])\n",
    "        else:\n",
    "            samples = label_df\n",
    "            df.loc[samples.index, 'sampled'] = True\n",
    "            dataset = pd.concat([dataset, samples])\n",
    "    dataset = dataset.drop(\"sampled\",axis=1)\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    training_datasets.append(dataset)\n",
    "\n",
    "# The output of this cell will create a list training_datasets which contains 3 10-shot dataset"
   ],
   "id": "0f99e995-1a52-4c37-bc9f-bf8d3e7ae18d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data"
   ],
   "id": "726891bb-b9ab-4ab9-8fbe-42fb247422ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_datasets.pkl', 'wb') as file:\n",
    "    pickle.dump(training_datasets, file)\n",
    "with open('val_data.pkl', 'wb') as file:\n",
    "    pickle.dump(val_data, file)\n",
    "with open('test_data.pkl', 'wb') as file:\n",
    "    pickle.dump(test_data, file)\n",
    "with open('train_data_full.pkl', 'wb') as file:\n",
    "    pickle.dump(train_data, file)"
   ],
   "id": "ca546797-e489-49d6-9093-82a30a529538"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "Upper and lower bound of n and alpha = 0.5 & 0.75"
   ],
   "id": "994ad77b-6a45-45e2-9c9f-35cc5f904c9e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ],
   "id": "ed52ca30-ad66-44d9-9b64-53a34826ec98"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Augmentation function"
   ],
   "id": "8e550503-ca1e-4184-955d-02ee8cd067e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(sentence, alpha=0.5 ):\n",
    "  sentence = sentence.split(\" \")\n",
    "  word_index = [i for i in range(len(sentence)) if sentence[i].lower() not in stop_words]\n",
    "  n = int(alpha*len(word_index))\n",
    "  n_random = random.sample(word_index, n)\n",
    "  for num in n_random:\n",
    "    word = sentence[num]\n",
    "    synonyms = []\n",
    "    for synset in wordnet.synsets(word):\n",
    "      for synonym in synset.lemmas():\n",
    "        synonyms.append(synonym.name())\n",
    "    if len(synonyms)>=2:\n",
    "      sentence[num] = synonyms[1]\n",
    "    else:\n",
    "      pass\n",
    "  return \" \".join(sentence)"
   ],
   "id": "29ae2e03-b3d6-41dd-b5f6-d238e9ebe096"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply data augmentation on each of the three training datasets"
   ],
   "id": "cf5b8ab0-377b-4b42-a52d-00707a691453"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_datasets = []\n",
    "for train_data in training_datasets:\n",
    "  augmented_data = train_data.copy()\n",
    "  augmented_data[\"speech_text\"] = augmented_data[\"speech_text\"].apply(augmentation, alpha=0.6)\n",
    "  augmented_data = pd.concat([train_data, augmented_data])\n",
    "  augmented_datasets.append(augmented_data)"
   ],
   "id": "c91f32a2-fee0-42ed-9200-cbb04eeb16f3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the augmented_data"
   ],
   "id": "db4d6f03-8649-414f-984a-83c9be0ae3d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('augmented_datasets.pkl', 'wb') as file:\n",
    "    pickle.dump(augmented_datasets, file)"
   ],
   "id": "cc0059ca-5c0a-43b5-bc2e-e11976e94581"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output of this Notebook\n",
    "\n",
    "This notebook will generate 4 files as mentioned below :\n",
    "\n",
    "-   training_datasets.pkl\n",
    "\n",
    "-   val_data.pkl\n",
    "\n",
    "-   test_data.pkl\n",
    "\n",
    "-   augmented_datasets.pkl"
   ],
   "id": "45cdd287-9c2d-4fc6-a284-bd44568465c9"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
