{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing the paper “Full few shot learning for intent classification.”"
   ],
   "id": "8f98db78-56b7-4bc4-a8ea-41c14f130e41"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot learning\n",
    "\n",
    "Few-shot learning is an adaptive paradigm that empowers models to excel even in scenarios with minimal training examples. By leveraging prior knowledge from related tasks or domains, these models swiftly learn new tasks with a handful of examples. Employing transferable knowledge, meta-learning, or data augmentation, few-shot learning unlocks remarkable generalization capabilities. It proves invaluable in practical applications, ranging from medical diagnosis to natural language understanding. With the ability to extrapolate from scarce data, few-shot learning holds promise for addressing the challenges of data scarcity, enabling AI systems to swiftly adapt and thrive in various contexts, while reducing the need for massive datasets and extensive training."
   ],
   "id": "89a710ab-ea86-49fd-9656-33c81a9827e9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full few shot learning\n",
    "\n",
    "Full few-shot learning enhances models’ abilities with small data. Unlike standard few-shot learning that uses a few examples per task, full few-shot learning gets more examples for each task. This helps models understand tasks better and work well with limited data. It’s like learning from a complete picture instead of just a small part. This approach makes models smarter across different tasks, from recognizing pictures to understanding language. By learning from a broader perspective, full few-shot learning solves the problem of having not much data and helps AI do a great job even with a small amount of information."
   ],
   "id": "9c873a22-e0c6-4f86-9aa7-dfccb512f185"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent classification\n",
    "\n",
    "Intent classification is like teaching a computer to understand what someone wants. Imagine you’re chatting with a virtual assistant, and you say, “Set an alarm for 7 AM.” Intent classification helps the computer figure out that your intention is to set an alarm. It’s about training the computer to recognize different purposes or intentions behind what people say. This skill is essential for making chatbots and voice assistants work better. By learning from lots of examples, the computer becomes good at identifying different intentions, making conversations with machines more helpful and natural."
   ],
   "id": "7d7b307c-9aa8-4a09-8fdd-154ed1ab2157"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT (Bidirectional Encoder Representation for Transformers)\n",
    "\n",
    "BERT, short for Bidirectional Encoder Representation for Transformers, is a groundbreaking language model. Imagine a computer program that understands sentences not just word by word, but also by considering the words before and after. This two-way thinking helps BERT grasp deep language meanings and patterns. It’s like teaching a computer to read between the lines. This superpower makes BERT awesome for many language tasks, from understanding texts to answering questions. It’s pre-trained on tons of data, so it already knows a lot about language. This makes it versatile and powerful, transforming how computers understand and work with human language."
   ],
   "id": "f9b75c60-dbf9-4b8d-b0a5-fd9a91762fcf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "Below are some of the libraries that are mandatory to install.\n",
    "\n",
    "-   [transformers](https://pypi.org/project/transformers/)\n",
    "\n",
    "-   [datasets](https://pypi.org/project/datasets/)\n",
    "\n",
    "-   [accelerate](https://pypi.org/project/accelerate/)\n",
    "\n",
    "-   [nltk](https://pypi.org/project/nltk/)"
   ],
   "id": "bbf27f5c-d6c0-424f-aaee-6aa7886a56d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install accelerate -U\n",
    "!pip install nltk"
   ],
   "id": "7861c657-6cdb-4fe6-86d9-37db01506ad9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "[HWU64](https://github.com/xliuhw/NLU-Evaluation-Data/) dataset is used by the paper we are going to reproduce and it contains natural language data for human-robot interaction in home domain which was collected and annotated for evaluating NLU Services/platforms.\n",
    "\n",
    "The above github link contains\n",
    "\n",
    "-   [Collected-Original-Data](https://github.com/xliuhw/NLU-Evaluation-Data/tree/master/Collected-Original-Data)\n",
    "\n",
    "-   [CrossValidation-Data](https://github.com/xliuhw/NLU-Evaluation-Data/tree/master/CrossValidation/autoGeneFromRealAnno/autoGene_2018_03_22-13_01_25_169/CrossValidation)\n",
    "\n",
    "In the paper it’s given that the author used a given number of training and test data but you are not sure that from which of the above data they obtained that number.\n",
    "\n",
    "Below we have 2 notebooks that have code to load data from any of all three datafolder and you can give a try to both and see through which data we are able to get equivalent results to what the author mentioned.\n",
    "\n",
    "-   [Notebook(Collected-Original-Data)](/)\n",
    "\n",
    "-   [Notebook(CrossValidation-Data)](/)"
   ],
   "id": "956045b5-cf54-4af1-b72f-a90d5946e4d2"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
